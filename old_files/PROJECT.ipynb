{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fad247",
   "metadata": {},
   "source": [
    "# This file sucks!\n",
    "\n",
    "It throws a FileNotFoundError when I try to run it:\n",
    "- FileNotFoundError: [Errno 2] No such file or directory: './data_cleaned/orders_with_receivals.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de319cba",
   "metadata": {},
   "source": [
    "# Overview of project\n",
    "We are provided historic data of raw material deliveries and orders through the end of 2024. GOAL: Develop a model that forecasts the cumulative weight of incoming deliveries of each raw material from Jan 1, 2025, up to any specified end date between Jan 1 and May 31, 2025.\n",
    "\n",
    "- recievals = historical records of material recievals\n",
    "- purchase_orders = ordered quantities and expected deliv\n",
    "- materials(opt) = metadata on various raw materials\n",
    "- transportation(opt) = transport-related data\n",
    "\n",
    "QuantileLoss0.2(Fi,Ai) = max(0.2*(Ai − Fi), 0.8*(Fi − Ai)).\n",
    "\n",
    "rm_id = unique identifer for raw material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d52f776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "purchase_order_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "purchase_order_item_no_order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "quantity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delivery_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_id_order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_version",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_date_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modified_date_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unit_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unit",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rm_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "product_id_receival",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "purchase_order_item_no_receival",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "receival_item_no",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "batch_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_arrival",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "receival_status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "net_weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "supplier_id",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "64a1aed2-99c7-42ec-8df6-0523bbbcfb89",
       "rows": [
        [
         "0",
         "1",
         "1",
         "-14.0",
         "2003-05-12 00:00:00.0000000 +02:00",
         "91900143",
         "1",
         "2003-05-12 10:00:48.0000000 +00:00",
         "2004-06-15 06:16:18.0000000 +00:00",
         null,
         null,
         "2",
         "Closed",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "22",
         "1",
         "23880.0",
         "2003-05-27 00:00:00.0000000 +02:00",
         "91900160",
         "1",
         "2003-05-27 12:42:07.0000000 +00:00",
         "2012-06-29 09:41:13.0000000 +00:00",
         null,
         null,
         "2",
         "Closed",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_order_id</th>\n",
       "      <th>purchase_order_item_no_order</th>\n",
       "      <th>quantity</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>product_id_order</th>\n",
       "      <th>product_version</th>\n",
       "      <th>created_date_time</th>\n",
       "      <th>modified_date_time</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>rm_id</th>\n",
       "      <th>product_id_receival</th>\n",
       "      <th>purchase_order_item_no_receival</th>\n",
       "      <th>receival_item_no</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>date_arrival</th>\n",
       "      <th>receival_status</th>\n",
       "      <th>net_weight</th>\n",
       "      <th>supplier_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>2003-05-12 00:00:00.0000000 +02:00</td>\n",
       "      <td>91900143</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-05-12 10:00:48.0000000 +00:00</td>\n",
       "      <td>2004-06-15 06:16:18.0000000 +00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>23880.0</td>\n",
       "      <td>2003-05-27 00:00:00.0000000 +02:00</td>\n",
       "      <td>91900160</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-05-27 12:42:07.0000000 +00:00</td>\n",
       "      <td>2012-06-29 09:41:13.0000000 +00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_order_id  purchase_order_item_no_order  quantity  \\\n",
       "0                  1                             1     -14.0   \n",
       "1                 22                             1   23880.0   \n",
       "\n",
       "                        delivery_date  product_id_order  product_version  \\\n",
       "0  2003-05-12 00:00:00.0000000 +02:00          91900143                1   \n",
       "1  2003-05-27 00:00:00.0000000 +02:00          91900160                1   \n",
       "\n",
       "                    created_date_time                  modified_date_time  \\\n",
       "0  2003-05-12 10:00:48.0000000 +00:00  2004-06-15 06:16:18.0000000 +00:00   \n",
       "1  2003-05-27 12:42:07.0000000 +00:00  2012-06-29 09:41:13.0000000 +00:00   \n",
       "\n",
       "   unit_id unit  ...  status rm_id  product_id_receival  \\\n",
       "0      NaN  NaN  ...  Closed   NaN                  NaN   \n",
       "1      NaN  NaN  ...  Closed   NaN                  NaN   \n",
       "\n",
       "   purchase_order_item_no_receival  receival_item_no  batch_id  date_arrival  \\\n",
       "0                              NaN               NaN       NaN           NaN   \n",
       "1                              NaN               NaN       NaN           NaN   \n",
       "\n",
       "  receival_status net_weight  supplier_id  \n",
       "0             NaN        NaN          NaN  \n",
       "1             NaN        NaN          NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to explore the data\n",
    "\n",
    "# First I want to check the difference between purchase orders\n",
    "# and recievals. How much was the difference between the two?\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "data_orders = pd.read_csv('data/kernel/purchase_orders.csv')\n",
    "data_receivals = pd.read_csv('data/kernel/receivals.csv')\n",
    "\n",
    "# Link the 5 first data orders to the recievals\n",
    "data = pd.merge(data_orders.head(5), data_receivals, on='purchase_order_id', suffixes=('_order', '_receival'), how='left')\n",
    "\n",
    "data.head(2)\n",
    "\n",
    "# NOT EVERY ORDER HAS A RECEIVAL? Oh... it makes sense cause some orders are never received? But I put the 5 in the head.... 5....\n",
    "# 5 whole orders are not received? That seems like a lot.... Nah maybe it's just purchase_order_id is a bad key to merge on.\n",
    "# Let's try purchase_order_item_no... # Absolutely not. I forgot it was like simple 1 etc...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9a8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "563\n"
     ]
    }
   ],
   "source": [
    "# Count all rows with quantity ordered negative\n",
    "print(data_orders['quantity'].lt(0).sum())\n",
    "\n",
    "print(data_orders['quantity'].eq(150000).sum())\n",
    "# 6 rows with negative quantity... prob wrong.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9676afc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [purchase_order_id, purchase_order_item_no_order, quantity, delivery_date, product_id_order, product_version, created_date_time, modified_date_time, unit_id, unit, status_id, status, rm_id, product_id_transport, purchase_order_item_no_transport, receival_item_no, batch_id, transporter_name, vehicle_no, unit_status, vehicle_start_weight, vehicle_end_weight, gross_weight, tare_weight, net_weight, wood, ironbands, plastic, water, ice, other, chips, packaging, cardboard]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# I want to check the transportation of the 5 orders in the head\n",
    "data_transport = pd.read_csv('data/extended/transportation.csv')\n",
    "\n",
    "data = pd.merge(data_orders.head(5), data_transport, on='purchase_order_id', suffixes=('_order', '_transport'))\n",
    "\n",
    "print(data)\n",
    "\n",
    "# Observation: Not all orders are transported either...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c110812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to check the material details of the 5 orders in the head\n",
    "# NVM... cooked... orders have nothing to directly link to materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ff303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OKAY! Let's try to drop all the orders with no recievals maybe? And try to predict? But in a real scenario I probably shouldn't\n",
    "# Cause maybe the orders with no recievals are equal to 0 recieved? But I don't know if that's true. Gotta test\n",
    "# So try 2 stuff: 1. drop the orders with no recievals, 2. set the recievals to 0 if no recievals\n",
    "\n",
    "# But first I neeed to know what my model will predict? Like will I get orders and recievals? Or just predict by the order prev?\n",
    "# Okay I don't think I'll get more orders in the future, so I guess I just have to predict based on previous orders\n",
    "\n",
    "# Purchase orders have an expected delivery_date though.\n",
    "# They are using YYYY-MM-DD format I guess\n",
    "# They want from 2025-01-01 to 2025-05-31\n",
    "# We got some deliveries expected in 2025-03-XX, but none after, so we prob need to predict that there will be more orders.\n",
    "\n",
    "# By making a model that predicts the quantity ordered based on previous orders, I can then use that to predict future orders\n",
    "# I should prob make a model for each of the materials and then sum them up for each order date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23cab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122590, 20)\n",
      "(122537, 20)\n",
      "       purchase_order_id  purchase_order_item_no  quantity delivery_date  \\\n",
      "61798                NaN                     NaN       NaN           NaN   \n",
      "63356                NaN                     NaN       NaN           NaN   \n",
      "64105                NaN                     NaN       NaN           NaN   \n",
      "65448                NaN                     NaN       NaN           NaN   \n",
      "71981                NaN                     NaN       NaN           NaN   \n",
      "\n",
      "       product_id_order  product_version created_date_time modified_date_time  \\\n",
      "61798               NaN              NaN               NaN                NaN   \n",
      "63356               NaN              NaN               NaN                NaN   \n",
      "64105               NaN              NaN               NaN                NaN   \n",
      "65448               NaN              NaN               NaN                NaN   \n",
      "71981               NaN              NaN               NaN                NaN   \n",
      "\n",
      "       unit_id unit  status_id status  rm_id  product_id_receival  \\\n",
      "61798      NaN  NaN        NaN    NaN    NaN                  NaN   \n",
      "63356      NaN  NaN        NaN    NaN    NaN                  NaN   \n",
      "64105      NaN  NaN        NaN    NaN    NaN                  NaN   \n",
      "65448      NaN  NaN        NaN    NaN    NaN                  NaN   \n",
      "71981      NaN  NaN        NaN    NaN    NaN                  NaN   \n",
      "\n",
      "       receival_item_no  batch_id                date_arrival receival_status  \\\n",
      "61798                 0       NaN  2015-08-04 12:44:00 +02:00       Completed   \n",
      "63356                 0       NaN  2015-11-19 11:32:00 +01:00       Completed   \n",
      "64105                 0       NaN  2016-01-08 14:48:00 +01:00       Completed   \n",
      "65448                 0       NaN  2016-03-16 09:31:00 +01:00       Completed   \n",
      "71981                 0       NaN  2017-03-29 11:42:00 +02:00       Completed   \n",
      "\n",
      "       net_weight  supplier_id  \n",
      "61798         NaN        64997  \n",
      "63356         NaN        53377  \n",
      "64105         NaN        64997  \n",
      "65448         NaN        10001  \n",
      "71981         NaN        54008  \n"
     ]
    }
   ],
   "source": [
    "# Starting by dropping the orders with no recievals\n",
    "data = pd.merge(\n",
    "    data_orders,\n",
    "    data_receivals,\n",
    "    on=['purchase_order_id', 'purchase_order_item_no'],\n",
    "    suffixes=('_order', '_receival')\n",
    ")\n",
    "\n",
    "# 122537 rows, but recievals has 122590 rows. So some recievals are from orders not in the orders dataset?\n",
    "data_extra_receivals = pd.merge(\n",
    "    data_orders,\n",
    "    data_receivals,\n",
    "    on=['purchase_order_id', 'purchase_order_item_no'],\n",
    "    suffixes=('_order', '_receival'),\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "print(data_extra_receivals.shape)\n",
    "print(data.shape)\n",
    "# 122591 rows, so 54 extra recievals that are not in the orders dataset\n",
    "# Let's check if they are all from the same purchase_order_id\n",
    "\n",
    "# I want the data_extra_receivals rows that are not in data\n",
    "data_diff = pd.concat([data_extra_receivals, data]).drop_duplicates(keep=False)\n",
    "print(data_diff.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f5057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# Check recievals with no purchase order id or purchase order item no\n",
    "print(data_receivals['purchase_order_id'].isna().sum())\n",
    "print(data_receivals['purchase_order_item_no'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53ccbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay let me first try using the data with recievals and where the recievals can be linked to purchase\n",
    "data = pd.merge(\n",
    "    data_orders,\n",
    "    data_receivals,\n",
    "    on=['purchase_order_id', 'purchase_order_item_no'],\n",
    "    suffixes=('_order', '_receival'),\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b699d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Completed' 'Finished unloading' 'Planned' 'Start unloading']\n",
      "receival_status\n",
      "Completed             122448\n",
      "Finished unloading       106\n",
      "Start unloading           32\n",
      "Planned                    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/kernel/receivals.csv')\n",
    "print(data['receival_status'].unique())\n",
    "print(data['receival_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1ef6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found out that some materials cease to be ordered after some time. Maybe they are obsolete?\n",
    "# Some dates use different time zones than others\n",
    "# Some units are in KG, LBs and pounds --> Need to make them to KG and drop that column\n",
    "# Some materials stock are deleted in the materials file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cee73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "############## CLEANING THE PURCHASE ORDERS DATA ##############\n",
    "\n",
    "orders = pd.read_csv(\"./data/kernel/purchase_orders.csv\")\n",
    "\n",
    "# Make the orders with PUND in KGs, and change quantity accordingly\n",
    "# 1 PUND = 0,45359237 kilogram\n",
    "orders.loc[orders['unit'] == 'PUND', 'quantity'] = orders.loc[orders['unit'] == 'PUND', 'quantity'] * 0.45359237\n",
    "# Change the unit to KG too: orders.loc[orders['unit'] == 'PUND', 'unit'] = 'KG'\n",
    "# Drop unit_id and unit columns\n",
    "orders = orders.drop(columns=['unit_id', 'unit'])\n",
    "\n",
    "# Time is in GMT+2 which is Norway time\n",
    "# Make delivery_date, created_date_time and modified_date_time to GMT +2\n",
    "orders['delivery_date'] = pd.to_datetime(orders['delivery_date'], utc=True).dt.tz_convert('Etc/GMT-2')\n",
    "orders['created_date_time'] = pd.to_datetime(orders['created_date_time'], utc=True).dt.tz_convert('Etc/GMT-2')\n",
    "orders['modified_date_time'] = pd.to_datetime(orders['modified_date_time'], utc=True).dt.tz_convert('Etc/GMT-2')\n",
    "\n",
    "# Save the cleaned data to a new CSV file in data_cleaned folder\n",
    "#orders.to_csv('./data_cleaned/purchase_orders_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd05ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLEANING THE RECEIVALS DATA ###\n",
    "receivals = pd.read_csv(\"./data/kernel/receivals.csv\")\n",
    "\n",
    "# Make the date_arrival to GMT +2\n",
    "receivals['date_arrival'] = pd.to_datetime(receivals['date_arrival'], utc=True).dt.tz_convert('Etc/GMT-2')\n",
    "# Save the cleaned data to a new CSV file in data_cleaned folder\n",
    "receivals.to_csv('./data_cleaned/receivals_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8136f941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133409, 20)\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Merge orders and receivals directly, then aggregate the recievals per order line\n",
    "# This will create duplicate rows for orders with multiple recievals, but we can aggregate them\n",
    "\n",
    "# --- Load data ---\n",
    "orders = pd.read_csv(\n",
    "    \"./data_cleaned/purchase_orders_cleaned.csv\",\n",
    "    parse_dates=[\"delivery_date\", \"created_date_time\", \"modified_date_time\"]\n",
    ")\n",
    "receivals = pd.read_csv(\n",
    "    \"./data_cleaned/receivals_cleaned.csv\",\n",
    "    parse_dates=[\"date_arrival\"]\n",
    ")\n",
    "\n",
    "# --- Merge orders and receivals WITHOUT aggregation ---\n",
    "orders_with_receivals = orders.merge(\n",
    "    receivals,\n",
    "    on=[\"purchase_order_id\", \"purchase_order_item_no\"],\n",
    "    how=\"left\",\n",
    "    suffixes=('_order', '_receival')\n",
    ")\n",
    "\n",
    "# --- Fill missing values for orders with no receivals ---\n",
    "orders_with_receivals[\"net_weight\"] = orders_with_receivals[\"net_weight\"].fillna(0)\n",
    "orders_with_receivals[\"date_arrival\"] = pd.to_datetime(orders_with_receivals[\"date_arrival\"])\n",
    "\n",
    "# --- Derived features ---\n",
    "orders_with_receivals[\"fill_fraction\"] = orders_with_receivals[\"net_weight\"] / orders_with_receivals[\"quantity\"]\n",
    "orders_with_receivals[\"lead_time\"] = (\n",
    "    orders_with_receivals[\"date_arrival\"] - orders_with_receivals[\"delivery_date\"]\n",
    ").dt.days\n",
    "orders_with_receivals[\"lead_time\"] = orders_with_receivals[\"lead_time\"].fillna(0)\n",
    "\n",
    "# --- Save result ---\n",
    "#orders_with_receivals.to_csv(\"./data_cleaned/orders_with_receivals_detailed.csv\", index=False)\n",
    "\n",
    "print(orders_with_receivals.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb3ceae",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_cleaned/orders_with_receivals.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m orders_merged = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data_cleaned/orders_with_receivals.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# print how many orders have value for total_received_qty that is different from 0\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m((orders_merged[\u001b[33m'\u001b[39m\u001b[33mtotal_received_qty\u001b[39m\u001b[33m'\u001b[39m] != \u001b[32m0\u001b[39m).sum())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Schreibtisch/semester7/moderne-maskinlæring-i-praksis-TDT4173/group-project/main_predict_stock/christian/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Schreibtisch/semester7/moderne-maskinlæring-i-praksis-TDT4173/group-project/main_predict_stock/christian/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Schreibtisch/semester7/moderne-maskinlæring-i-praksis-TDT4173/group-project/main_predict_stock/christian/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Schreibtisch/semester7/moderne-maskinlæring-i-praksis-TDT4173/group-project/main_predict_stock/christian/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Schreibtisch/semester7/moderne-maskinlæring-i-praksis-TDT4173/group-project/main_predict_stock/christian/.venv/lib/python3.14/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data_cleaned/orders_with_receivals.csv'"
     ]
    }
   ],
   "source": [
    "orders_merged = pd.read_csv(\"./data_cleaned/orders_with_receivals.csv\")\n",
    "\n",
    "# print how many orders have value for total_received_qty that is different from 0\n",
    "print((orders_merged['total_received_qty'] != 0).sum())\n",
    "print((orders_merged['total_received_qty'] == 0).sum())\n",
    "print(orders_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f0e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11026\n",
      "(133409, 20)\n"
     ]
    }
   ],
   "source": [
    "# Check how many orders with no receivals\n",
    "print((orders_with_receivals['net_weight'] == 0).sum())\n",
    "print(orders_with_receivals.shape)\n",
    "# 122 591 rows, so 54 extra recievals that are not in the orders dataset\n",
    "# 11 026 orders with no receivals\n",
    "# 122 537 + 11 026 = 133 563\n",
    "# So it doesn't make sense that I get 133 409 rows when merging\n",
    "# Errr... whatever for now I guess\n",
    "# Ehhrm why do I get 10 887 above and 11 026 here? errrm...\n",
    "\n",
    "# TODO: FIND OUT WHY THE DIFFERENCE IN ROWS WHEN MERGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rm_id  avg_fill_fraction  avg_lead_time  avg_weekly_order_qty\n",
      "0  342.0           0.479615           23.0             42.573099\n",
      "1  343.0           0.004804         -642.0           3708.771930\n"
     ]
    }
   ],
   "source": [
    "# Okay now use orders_with_receivals_detailed.csv to make a model that predicts net_weight based on previous orders\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "orders = pd.read_csv(\"./data_cleaned/purchase_orders_cleaned.csv\", parse_dates=[\"delivery_date\", \"created_date_time\", \"modified_date_time\"])\n",
    "receivals = pd.read_csv(\"./data_cleaned/receivals_cleaned.csv\", parse_dates=[\"date_arrival\"])\n",
    "orders_with_receivals = pd.read_csv(\"./data_cleaned/orders_with_receivals_detailed.csv\", parse_dates=[\"delivery_date\", \"created_date_time\", \"modified_date_time\", \"date_arrival\"])\n",
    "\n",
    "# Make sure dates are tz-naive for calculations\n",
    "orders_with_receivals['date_arrival'] = orders_with_receivals['date_arrival'].dt.tz_convert(None)\n",
    "orders_with_receivals['delivery_date'] = orders_with_receivals['delivery_date'].dt.tz_convert(None)\n",
    "orders_with_receivals['created_date_time'] = orders_with_receivals['created_date_time'].dt.tz_convert(None)\n",
    "orders_with_receivals['modified_date_time'] = orders_with_receivals['modified_date_time'].dt.tz_convert(None)\n",
    "\n",
    "# Mean fill_fraction, lead_time and weekly order quantity per material\n",
    "\n",
    "material_stats = orders_with_receivals.groupby('rm_id').agg(\n",
    "    avg_fill_fraction=('fill_fraction', 'mean'),\n",
    "    avg_lead_time=('lead_time', 'mean'),\n",
    "    avg_weekly_order_qty=('quantity', lambda x: x.sum() / ((orders_with_receivals['delivery_date'].max() - orders_with_receivals['delivery_date'].min()).days / 7))\n",
    ").reset_index()\n",
    "\n",
    "print(material_stats.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415fa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19430, 20)\n",
      "(6340, 20)\n"
     ]
    }
   ],
   "source": [
    "# But when I think closely. Why don't I make a model that trains on\n",
    "# data up to 2013 and predicts 2014? Cause then I can actually see if it works\n",
    "# So I need to split the data into train and test based on date\n",
    "\n",
    "# Sidenote: I just thought about something for transportation: Mby some transporter names are more reliable than others?\n",
    "# Like some transporters always deliver on time, while others are late. They prob get better as time goes on too?\n",
    "\n",
    "# Okay let's start with splitting the data into train and test based on date\n",
    "train_data = orders_with_receivals[orders_with_receivals['delivery_date'] < '2024-01-01']\n",
    "test_data = orders_with_receivals[orders_with_receivals['delivery_date'] >= '2024-01-01']\n",
    "\n",
    "# The thing is I have so much data from previous years so I feel like I will overfit if I use all of it\n",
    "# So I will use only the most recent 3 years of data for training? Hmm some years we got events like\n",
    "# COVID or NM in skiing that might make some years different too\n",
    "\n",
    "train_data = train_data[train_data['delivery_date'] >= '2021-01-01']\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.14",
   "language": "python",
   "name": "ml3.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
