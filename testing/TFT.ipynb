{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53d50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test2024 = pd.read_csv(\"../validation/testing2024manual.csv\")\n",
    "prediction_mapping = pd.read_csv(\"../data/prediction_mapping.csv\")\n",
    "\n",
    "merged = test2024.merge(prediction_mapping, on=\"ID\")\n",
    "\n",
    "filtered = merged[merged.groupby(\"rm_id\")[\"predicted_weight\"].transform(\"sum\") > 0]\n",
    "\n",
    "agg_df = filtered.groupby(\"rm_id\", as_index=False).agg({\n",
    "    \"predicted_weight\": \"max\",\n",
    "}).sort_values(\"predicted_weight\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de8cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_rm_ids = set(agg_df[\"rm_id\"])\n",
    "\n",
    "receivals = pd.read_csv(\"../data_cleaned/orders_with_receivals_detailed.csv\")\n",
    "receivals_filtered = receivals[receivals[\"rm_id\"].isin(used_rm_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9833f254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rm_id               date_arrival  net_weight\n",
      "34057   2130.0  2012-03-14 10:58:00+02:00      8920.0\n",
      "34058   2130.0  2012-03-14 10:58:00+02:00      4120.0\n",
      "34059   2130.0  2012-03-20 17:34:00+02:00      2236.0\n",
      "34060   2130.0  2012-03-20 17:34:00+02:00      4188.0\n",
      "34065   2142.0  2012-03-14 10:58:00+02:00       680.0\n",
      "...        ...                        ...         ...\n",
      "133275  2142.0  2024-12-12 12:41:00+02:00      3920.0\n",
      "133276  2143.0  2024-12-12 12:41:00+02:00       260.0\n",
      "133288  3381.0  2024-12-18 12:18:00+02:00      2806.0\n",
      "133292  3901.0  2024-12-17 16:05:00+02:00     12540.0\n",
      "133293  3901.0  2024-12-19 11:40:00+02:00     14040.0\n",
      "\n",
      "[60444 rows x 3 columns]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# Select columns: rm_id, date_arrival, net_weight\n",
    "selected = receivals_filtered[[\"rm_id\", \"date_arrival\", \"net_weight\"]]\n",
    "\n",
    "print(selected)\n",
    "print(len(used_rm_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b9240cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\Desktop\\ML append prosjekt\\append_consulting_project\\.venv39\\lib\\site-packages\\lightning_fabric\\__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\Desktop\\ML append prosjekt\\append_consulting_project\\.venv39\\lib\\site-packages\\lightning_fabric\\__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesDataSet, TemporalFusionTransformer, Baseline, GroupNormalizer, QuantileLoss\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader  \u001b[38;5;66;03m# Correct import for DataLoader\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\david\\Desktop\\ML append prosjekt\\append_consulting_project\\.venv39\\lib\\site-packages\\pytorch_forecasting\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mPyTorch Forecasting package for timeseries forecasting with PyTorch.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.4.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     EncoderNormalizer,\n\u001b[0;32m      9\u001b[0m     GroupNormalizer,\n\u001b[0;32m     10\u001b[0m     MultiNormalizer,\n\u001b[0;32m     11\u001b[0m     NaNLabelEncoder,\n\u001b[0;32m     12\u001b[0m     TimeSeriesDataSet,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     MAE,\n\u001b[0;32m     16\u001b[0m     MAPE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     QuantileLoss,\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     GRU,\n\u001b[0;32m     36\u001b[0m     LSTM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     get_rnn,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\david\\Desktop\\ML append prosjekt\\append_consulting_project\\.venv39\\lib\\site-packages\\pytorch_forecasting\\data\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mDatasets, etc. for timeseries data.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mHandling timeseries data is not trivial. It requires special treatment.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mThis sub-package provides the necessary tools to abstracts the necessary work.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     EncoderNormalizer,\n\u001b[0;32m     10\u001b[0m     GroupNormalizer,\n\u001b[0;32m     11\u001b[0m     MultiNormalizer,\n\u001b[0;32m     12\u001b[0m     NaNLabelEncoder,\n\u001b[0;32m     13\u001b[0m     TorchNormalizer,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msamplers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSynchronizedBatchSampler\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries, TimeSeriesDataSet\n",
      "File \u001b[1;32mc:\\Users\\david\\Desktop\\ML append prosjekt\\append_consulting_project\\.venv39\\lib\\site-packages\\pytorch_forecasting\\data\\encoders.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rnn\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InitialParameterRepresenterMixIn\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_plus_one\u001b[39m(x):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\david\\Desktop\\ML append prosjekt\\append_consulting_project\\.venv39\\lib\\site-packages\\pytorch_forecasting\\utils\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mPyTorch Forecasting package for timeseries forecasting with PyTorch.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     InitialParameterRepresenterMixIn,\n\u001b[0;32m      7\u001b[0m     OutputMixIn,\n\u001b[0;32m      8\u001b[0m     TupleOutputMixIn,\n\u001b[0;32m      9\u001b[0m     apply_to_list,\n\u001b[0;32m     10\u001b[0m     autocorrelation,\n\u001b[0;32m     11\u001b[0m     concat_sequences,\n\u001b[0;32m     12\u001b[0m     create_mask,\n\u001b[0;32m     13\u001b[0m     detach,\n\u001b[0;32m     14\u001b[0m     get_embedding_size,\n\u001b[0;32m     15\u001b[0m     groupby_apply,\n\u001b[0;32m     16\u001b[0m     integer_histogram,\n\u001b[0;32m     17\u001b[0m     masked_op,\n\u001b[0;32m     18\u001b[0m     move_to_device,\n\u001b[0;32m     19\u001b[0m     padded_stack,\n\u001b[0;32m     20\u001b[0m     profile,\n\u001b[0;32m     21\u001b[0m     redirect_stdout,\n\u001b[0;32m     22\u001b[0m     repr_class,\n\u001b[0;32m     23\u001b[0m     to_list,\n\u001b[0;32m     24\u001b[0m     unpack_sequence,\n\u001b[0;32m     25\u001b[0m     unsqueeze_like,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialParameterRepresenterMixIn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputMixIn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsqueeze_like\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\david\\Desktop\\ML append prosjekt\\append_consulting_project\\.venv39\\lib\\site-packages\\pytorch_forecasting\\utils\\_utils.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Union\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightning'"
     ]
    }
   ],
   "source": [
    "# Temporal Fusion Transformer (TFT) forecasting for receival prediction\n",
    "# Install dependencies if needed\n",
    "# !pip install pytorch-lightning pytorch-forecasting torch --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline, GroupNormalizer, QuantileLoss\n",
    "from torch.utils.data import DataLoader  # Correct import for DataLoader\n",
    "\n",
    "# Prepare data\n",
    "receivals_filtered[\"date_arrival\"] = pd.to_datetime(receivals_filtered[\"date_arrival\"])\n",
    "# Convert rm_id to string for categorical encoding\n",
    "receivals_filtered[\"rm_id\"] = receivals_filtered[\"rm_id\"].astype(str)\n",
    "receivals_filtered[\"time_idx\"] = (receivals_filtered[\"date_arrival\"] - receivals_filtered[\"date_arrival\"].min()).dt.days\n",
    "\n",
    "# Only use data after 2017 for training\n",
    "df_hist = receivals_filtered[receivals_filtered[\"date_arrival\"].dt.year > 2017].copy()\n",
    "\n",
    "# Define max prediction length (e.g., 12 months ahead)\n",
    "max_prediction_length = 365  # days\n",
    "max_encoder_length = 365 * 3  # use last 3 years for context\n",
    "\n",
    "# Prepare TimeSeriesDataSet\n",
    "training = TimeSeriesDataSet(\n",
    "    df_hist,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"net_weight\",\n",
    "    group_ids=[\"rm_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # allow shorter history\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"rm_id\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_reals=[\"net_weight\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"rm_id\"], transformation=\"softplus\"),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True, # <-- Fix for irregular time steps\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(training, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize TFT model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # Quantile regression\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Train model (quick demo, adjust epochs for real use)\n",
    "# Use 'accelerator' and 'devices' instead of deprecated 'gpus' argument\n",
    "trainer = Trainer(max_epochs=10, accelerator=\"cpu\", devices=1)  # set accelerator=\"gpu\", devices=1 for GPU\n",
    "trainer.fit(tft, train_dataloaders=train_dataloader)\n",
    "\n",
    "# Predict future receivals for each rm_id\n",
    "# Prepare prediction data for 2025\n",
    "last_time_idx = df_hist[\"time_idx\"].max()\n",
    "future_df = []\n",
    "for rm_id in df_hist[\"rm_id\"].unique():\n",
    "    for i in range(1, max_prediction_length + 1):\n",
    "        future_df.append({\n",
    "            \"rm_id\": rm_id,\n",
    "            \"time_idx\": last_time_idx + i,\n",
    "            \"date_arrival\": df_hist[df_hist[\"rm_id\"] == rm_id][\"date_arrival\"].max() + pd.Timedelta(days=i),\n",
    "        })\n",
    "future_df = pd.DataFrame(future_df)\n",
    "\n",
    "# Merge with last known net_weight (required for TFT input)\n",
    "future_df = future_df.merge(\n",
    "    df_hist[[\"rm_id\", \"net_weight\"]].groupby(\"rm_id\").last().reset_index(),\n",
    "    on=\"rm_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Create prediction TimeSeriesDataSet\n",
    "prediction = TimeSeriesDataSet.from_dataset(training, future_df, predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
    "pred_dataloader = DataLoader(prediction, batch_size=64, shuffle=False)\n",
    "\n",
    "# Run prediction\n",
    "raw_predictions, x = tft.predict(pred_dataloader, mode=\"raw\", return_x=True)\n",
    "# Extract mean predictions\n",
    "predicted_weights = raw_predictions[\"prediction\"].mean(axis=2).flatten()\n",
    "\n",
    "# Build simulated receivals DataFrame\n",
    "simulated_df = future_df.copy()\n",
    "simulated_df[\"net_weight\"] = predicted_weights\n",
    "print(\"TFT-based forecasting complete.\")\n",
    "print(f\"Total simulated receivals for 2025: {len(simulated_df)}\")\n",
    "print(simulated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06276289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tft class: <class 'pytorch_forecasting.models.temporal_fusion_transformer._tft.TemporalFusionTransformer'>\n",
      "tft module: pytorch_forecasting.models.temporal_fusion_transformer._tft\n",
      "Trainer class: <class 'pytorch_lightning.trainer.trainer.Trainer'>\n",
      "Trainer module: pytorch_lightning.trainer.trainer\n",
      "tft base classes: (<class 'pytorch_forecasting.models.temporal_fusion_transformer._tft.TemporalFusionTransformer'>, <class 'pytorch_forecasting.models.base._base_model.BaseModelWithCovariates'>, <class 'pytorch_forecasting.models.base._base_model.BaseModel'>, <class 'pytorch_forecasting.utils._utils.InitialParameterRepresenterMixIn'>, <class 'lightning.pytorch.core.module.LightningModule'>, <class 'lightning.fabric.utilities.device_dtype_mixin._DeviceDtypeModuleMixin'>, <class 'lightning.pytorch.core.mixins.hparams_mixin.HyperparametersMixin'>, <class 'lightning.pytorch.core.hooks.ModelHooks'>, <class 'lightning.pytorch.core.hooks.DataHooks'>, <class 'lightning.pytorch.core.hooks.CheckpointHooks'>, <class 'torch.nn.modules.module.Module'>, <class 'pytorch_forecasting.utils._utils.TupleOutputMixIn'>, <class 'object'>)\n",
      "Is tft a LightningModule? True\n",
      "Is tft a pl.LightningModule? True\n"
     ]
    }
   ],
   "source": [
    "# --- Diagnostic: Check module origins and inheritance ---\n",
    "print('tft class:', type(tft))\n",
    "print('tft module:', type(tft).__module__)\n",
    "print('Trainer class:', type(trainer))\n",
    "print('Trainer module:', type(trainer).__module__)\n",
    "import inspect\n",
    "print('tft base classes:', inspect.getmro(type(tft)))\n",
    "print('Is tft a LightningModule?', isinstance(tft, torch.nn.Module))\n",
    "print('Is tft a pl.LightningModule?', hasattr(tft, 'training_step'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "638e655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_df.to_csv(\"simulated_receivals_2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008bb364",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "prediction_mapping = pd.read_csv(\"../data/prediction_mapping.csv\", parse_dates=[\"forecast_start_date\", \"forecast_end_date\"])\n",
    "submission = sample_submission.merge(prediction_mapping, on=\"ID\")\n",
    "simulated_df = pd.read_csv(\"simulated_receivals_2025.csv\", parse_dates=[\"date_arrival\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f2ab9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for receival in simulated_df.itertuples():\n",
    "    rm_id = receival.rm_id\n",
    "    date_arrival = receival.date_arrival\n",
    "    net_weight = receival.net_weight\n",
    "    # Convert date_arrival to naive datetime for comparison\n",
    "    date_arrival_naive = date_arrival.replace(tzinfo=None)\n",
    "    submission.loc[\n",
    "        (submission['rm_id'] == rm_id) & (submission['forecast_end_date'] >= date_arrival_naive),\n",
    "        'predicted_weight'\n",
    "    ] += (net_weight*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e759940",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[[\"ID\", \"predicted_weight\"]]\n",
    "submission.to_csv(\"testing2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac12fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"testing2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b35b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rm_id  predicted_weight\n",
      "75    2130      6.009917e+06\n",
      "180   3865      2.117237e+06\n",
      "151   3126      1.819248e+06\n",
      "83    2140      1.670645e+06\n",
      "147   3122      1.637264e+06\n",
      "160   3282      1.525760e+06\n",
      "150   3125      1.462576e+06\n",
      "149   3124      1.024576e+06\n",
      "148   3123      1.002832e+06\n",
      "176   3781      9.871144e+05\n",
      "79    2134      6.253800e+05\n",
      "159   3265      4.949120e+05\n",
      "182   3901      4.429440e+05\n",
      "85    2142      3.663764e+05\n",
      "87    2144      2.637948e+05\n",
      "142   2981      2.551360e+05\n",
      "80    2135      2.384537e+05\n",
      "76    2131      2.293000e+05\n",
      "77    2132      1.388832e+05\n",
      "181   3883      1.175360e+05\n",
      "88    2145      1.114832e+05\n",
      "78    2133      1.029703e+05\n",
      "152   3142      9.710400e+04\n",
      "163   3421      9.254000e+04\n",
      "136   2741      9.111520e+04\n",
      "191   4263      8.025600e+04\n",
      "172   3642      5.952000e+04\n",
      "190   4222      5.915200e+04\n",
      "86    2143      5.849040e+04\n",
      "71    2125      3.602880e+04\n",
      "161   3362      2.980800e+04\n",
      "90    2147      2.336704e+04\n",
      "70    2124      1.680160e+04\n",
      "74    2129      1.331200e+04\n",
      "103   2161      5.184000e+03\n",
      "117   2341      0.000000e+00\n",
      "116   2323      0.000000e+00\n",
      "128   2402      0.000000e+00\n",
      "133   2521      0.000000e+00\n",
      "115   2322      0.000000e+00\n",
      "114   2304      0.000000e+00\n",
      "135   2601      0.000000e+00\n",
      "113   2302      0.000000e+00\n",
      "137   2742      0.000000e+00\n",
      "138   2761      0.000000e+00\n",
      "112   2285      0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "test_df = submission.merge(prediction_mapping, on=\"ID\")\n",
    "test_df = test_df.groupby(\"rm_id\", as_index=False).agg({\n",
    "    \"predicted_weight\": \"max\",\n",
    "}).sort_values(\"predicted_weight\", ascending=False)\n",
    "\n",
    "print(test_df[0:46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rm_id  predicted_weight\n",
      "75    2130      3.605950e+06\n",
      "180   3865      2.117237e+06\n",
      "151   3126      1.819248e+06\n",
      "83    2140      1.670645e+06\n",
      "147   3122      1.637264e+06\n",
      "..     ...               ...\n",
      "64    2001      0.000000e+00\n",
      "65    2061      0.000000e+00\n",
      "66    2102      0.000000e+00\n",
      "67    2121      0.000000e+00\n",
      "202   4501      0.000000e+00\n",
      "\n",
      "[203 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# SCALE SPECIFIC RM_ID DOWN\n",
    "testing_2130 = pd.read_csv(\"testing2025.csv\")\n",
    "testing_2130 = testing_2130.merge(prediction_mapping, on=\"ID\")\n",
    "\n",
    "testing_2130.loc[testing_2130['rm_id'] == 2130, 'predicted_weight'] *= 0.6\n",
    "\n",
    "testing = testing_2130.groupby(\"rm_id\", as_index=False).agg({\n",
    "    \"predicted_weight\": \"max\",\n",
    "}).sort_values(\"predicted_weight\", ascending=False)\n",
    "\n",
    "print(testing)\n",
    "testing_2130 = testing_2130[[\"ID\", \"predicted_weight\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8772cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2130.to_csv(\"testing2025_2130_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffee76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8291af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Forecasting version: 1.5.0\n",
      "PyTorch Lightning version: 2.5.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check installed versions of PyTorch Forecasting and PyTorch Lightning\n",
    "import pytorch_forecasting\n",
    "import pytorch_lightning\n",
    "print(\"PyTorch Forecasting version:\", pytorch_forecasting.__version__)\n",
    "print(\"PyTorch Lightning version:\", pytorch_lightning.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc700f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
