{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53d50a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m test2024 = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../validation/submission_2024receivals_scale07.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m prediction_mapping = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../data/prediction_mapping.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test2024 = pd.read_csv(\"../validation/submission_2024receivals_scale07.csv\")\n",
    "prediction_mapping = pd.read_csv(\"../data/prediction_mapping.csv\")\n",
    "\n",
    "merged = test2024.merge(prediction_mapping, on=\"ID\")\n",
    "\n",
    "filtered = merged[merged.groupby(\"rm_id\")[\"predicted_weight\"].transform(\"sum\") > 0]\n",
    "\n",
    "agg_df = filtered.groupby(\"rm_id\", as_index=False).agg({\n",
    "    \"predicted_weight\": \"max\",\n",
    "}).sort_values(\"predicted_weight\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3de8cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_rm_ids = set(agg_df[\"rm_id\"])\n",
    "\n",
    "receivals = pd.read_csv(\"../data_cleaned/orders_with_receivals_detailed.csv\")\n",
    "receivals_filtered = receivals[receivals[\"rm_id\"].isin(used_rm_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9833f254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rm_id               date_arrival  net_weight\n",
      "34057   2130.0  2012-03-14 10:58:00+02:00      8920.0\n",
      "34058   2130.0  2012-03-14 10:58:00+02:00      4120.0\n",
      "34059   2130.0  2012-03-20 17:34:00+02:00      2236.0\n",
      "34060   2130.0  2012-03-20 17:34:00+02:00      4188.0\n",
      "34065   2142.0  2012-03-14 10:58:00+02:00       680.0\n",
      "...        ...                        ...         ...\n",
      "133275  2142.0  2024-12-12 12:41:00+02:00      3920.0\n",
      "133276  2143.0  2024-12-12 12:41:00+02:00       260.0\n",
      "133288  3381.0  2024-12-18 12:18:00+02:00      2806.0\n",
      "133292  3901.0  2024-12-17 16:05:00+02:00     12540.0\n",
      "133293  3901.0  2024-12-19 11:40:00+02:00     14040.0\n",
      "\n",
      "[60444 rows x 3 columns]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# Select columns: rm_id, date_arrival, net_weight\n",
    "selected = receivals_filtered[[\"rm_id\", \"date_arrival\", \"net_weight\"]]\n",
    "\n",
    "print(selected)\n",
    "print(len(used_rm_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b9240cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA-based forecasting complete.\n",
      "Total simulated receivals for 2025: 5183\n",
      "Total predicted weight: 71,085,581\n",
      "Unique rm_ids with predictions: 36\n",
      "   rm_id date_arrival  net_weight\n",
      "0   3781   2025-10-15     13880.0\n",
      "1   3781   2025-10-21      9340.0\n",
      "2   3781   2025-03-11     20980.0\n",
      "3   3781   2025-10-04     22340.0\n",
      "4   3781   2025-08-22     22160.0\n"
     ]
    }
   ],
   "source": [
    "# ARIMA-based time series forecasting for receival prediction\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import warnings\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "simulated_receivals = []\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "for rm_id in agg_df[\"rm_id\"]:\n",
    "    df_rm = receivals_filtered[receivals_filtered[\"rm_id\"] == rm_id].copy()\n",
    "    if df_rm.empty:\n",
    "        continue\n",
    "    \n",
    "    df_rm = df_rm.sort_values(\"date_arrival\")\n",
    "    df_rm[\"date_arrival\"] = pd.to_datetime(df_rm[\"date_arrival\"])\n",
    "    \n",
    "    # Use only data after 2017 for forecasting\n",
    "    df_hist = df_rm[df_rm[\"date_arrival\"].dt.year > 2017].copy()\n",
    "    if len(df_hist) < 10:  # Need more data points for ARIMA\n",
    "        continue\n",
    "    \n",
    "    # Create monthly time series of total net_weight\n",
    "    df_hist.set_index(\"date_arrival\", inplace=True)\n",
    "    monthly_weights = df_hist[\"net_weight\"].resample('M').sum()\n",
    "    \n",
    "    # Remove months with zero weights for better ARIMA fitting\n",
    "    monthly_weights = monthly_weights[monthly_weights > 0]\n",
    "    \n",
    "    if len(monthly_weights) < 6:  # Need at least 6 months for ARIMA\n",
    "        continue\n",
    "    \n",
    "    # Analyze historical arrival patterns for this rm_id\n",
    "    df_hist_reset = df_hist.reset_index()\n",
    "    df_hist_reset['month'] = df_hist_reset['date_arrival'].dt.month\n",
    "    df_hist_reset['day_of_year'] = df_hist_reset['date_arrival'].dt.dayofyear\n",
    "    \n",
    "    # Calculate monthly distribution (probability of receivals per month)\n",
    "    monthly_counts = df_hist_reset['month'].value_counts().sort_index()\n",
    "    monthly_probs = monthly_counts / monthly_counts.sum()\n",
    "    \n",
    "    # Calculate day-of-year distribution for more granular patterns\n",
    "    dayofyear_counts = df_hist_reset['day_of_year'].value_counts()\n",
    "    \n",
    "    try:\n",
    "        # Fit ARIMA model - using auto order selection\n",
    "        # Try different ARIMA orders and select best based on AIC\n",
    "        best_aic = float('inf')\n",
    "        best_model = None\n",
    "        best_order = None\n",
    "        \n",
    "        # Test different ARIMA orders\n",
    "        for p in range(0, 3):\n",
    "            for d in range(0, 2):\n",
    "                for q in range(0, 3):\n",
    "                    try:\n",
    "                        model = ARIMA(monthly_weights, order=(p, d, q))\n",
    "                        fitted_model = model.fit()\n",
    "                        if fitted_model.aic < best_aic:\n",
    "                            best_aic = fitted_model.aic\n",
    "                            best_model = fitted_model\n",
    "                            best_order = (p, d, q)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        if best_model is None:\n",
    "            # Fallback to simple mean if ARIMA fails\n",
    "            monthly_pred = monthly_weights.mean()\n",
    "            n_receivals = max(1, int(monthly_weights.count() / len(monthly_weights.index) * 12))  # Average per month * 12\n",
    "        else:\n",
    "            # Forecast 12 months ahead (2025)\n",
    "            forecast_result = best_model.forecast(steps=12)\n",
    "            monthly_pred = max(0, forecast_result.mean())  # Take mean and ensure positive\n",
    "            \n",
    "            # Estimate number of receivals per month based on historical frequency\n",
    "            historical_monthly_counts = df_hist.resample('M')[\"net_weight\"].count()\n",
    "            avg_monthly_count = max(1, int(historical_monthly_counts.mean()))\n",
    "            n_receivals = avg_monthly_count * 12  # Scale to full year\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Fallback if ARIMA completely fails\n",
    "        monthly_pred = monthly_weights.mean()\n",
    "        n_receivals = max(1, len(df_hist) // 2)  # Conservative estimate\n",
    "    \n",
    "    if n_receivals <= 0:\n",
    "        continue\n",
    "    \n",
    "    # Generate predicted total weight for 2025 based on ARIMA forecast\n",
    "    total_predicted_weight = monthly_pred * 12  # 12 months\n",
    "    \n",
    "    # Cap total predicted weight to reasonable bounds (max of last 3 years)\n",
    "    yearly_totals = df_hist.resample('Y')[\"net_weight\"].sum()\n",
    "    if len(yearly_totals) > 0:\n",
    "        max_historical_year = yearly_totals.max()\n",
    "        total_predicted_weight = min(total_predicted_weight, max_historical_year * 1.2)  # Allow 20% growth\n",
    "    \n",
    "    # Sample individual receival weights from historical distribution\n",
    "    historical_weights = df_hist[\"net_weight\"][df_hist[\"net_weight\"] > 0]\n",
    "    if len(historical_weights) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Generate individual receivals\n",
    "    receivals_list = []\n",
    "    running_total = 0\n",
    "    \n",
    "    for i in range(n_receivals):\n",
    "        if running_total >= total_predicted_weight:\n",
    "            break\n",
    "            \n",
    "        # Sample weight from historical distribution\n",
    "        weight = np.random.choice(historical_weights)\n",
    "        \n",
    "        # Don't exceed total predicted weight\n",
    "        if running_total + weight > total_predicted_weight:\n",
    "            weight = max(0, total_predicted_weight - running_total)\n",
    "            if weight <= 0:\n",
    "                break\n",
    "        \n",
    "        # Generate date based on historical patterns for this rm_id\n",
    "        if len(monthly_probs) > 0:\n",
    "            # Sample month based on historical monthly distribution\n",
    "            sampled_month = np.random.choice(monthly_probs.index, p=monthly_probs.values)\n",
    "            \n",
    "            # Generate random day within that month\n",
    "            if sampled_month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "                max_day = 31\n",
    "            elif sampled_month in [4, 6, 9, 11]:\n",
    "                max_day = 30\n",
    "            else:  # February\n",
    "                max_day = 28  # Assuming non-leap year for 2025\n",
    "            \n",
    "            sampled_day = np.random.randint(1, max_day + 1)\n",
    "            \n",
    "            try:\n",
    "                arrival_date = pd.Timestamp(f\"2025-{sampled_month:02d}-{sampled_day:02d}\")\n",
    "            except:\n",
    "                # Fallback if invalid date\n",
    "                arrival_date = pd.Timestamp(\"2025-01-01\") + timedelta(days=np.random.randint(0, 365))\n",
    "        else:\n",
    "            # Fallback to uniform random if no historical patterns\n",
    "            start_date = pd.Timestamp(\"2025-01-01\")\n",
    "            random_days = np.random.randint(0, 365)\n",
    "            arrival_date = start_date + timedelta(days=random_days)\n",
    "        \n",
    "        receivals_list.append({\n",
    "            \"rm_id\": rm_id,\n",
    "            \"date_arrival\": arrival_date,\n",
    "            \"net_weight\": weight\n",
    "        })\n",
    "        \n",
    "        running_total += weight\n",
    "    \n",
    "    simulated_receivals.extend(receivals_list)\n",
    "\n",
    "simulated_df = pd.DataFrame(simulated_receivals)\n",
    "print(f\"ARIMA-based forecasting complete.\")\n",
    "print(f\"Total simulated receivals for 2025: {len(simulated_df)}\")\n",
    "if len(simulated_df) > 0:\n",
    "    print(f\"Total predicted weight: {simulated_df['net_weight'].sum():,.0f}\")\n",
    "    print(f\"Unique rm_ids with predictions: {simulated_df['rm_id'].nunique()}\")\n",
    "    print(simulated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "638e655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_df.to_csv(\"simulated_receivals_2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008bb364",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "prediction_mapping = pd.read_csv(\"../data/prediction_mapping.csv\", parse_dates=[\"forecast_start_date\", \"forecast_end_date\"])\n",
    "submission = sample_submission.merge(prediction_mapping, on=\"ID\")\n",
    "simulated_df = pd.read_csv(\"simulated_receivals_2025.csv\", parse_dates=[\"date_arrival\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f2ab9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for receival in simulated_df.itertuples():\n",
    "    rm_id = receival.rm_id\n",
    "    date_arrival = receival.date_arrival\n",
    "    net_weight = receival.net_weight\n",
    "    # Convert date_arrival to naive datetime for comparison\n",
    "    date_arrival_naive = date_arrival.replace(tzinfo=None)\n",
    "    submission.loc[\n",
    "        (submission['rm_id'] == rm_id) & (submission['forecast_end_date'] >= date_arrival_naive),\n",
    "        'predicted_weight'\n",
    "    ] += (net_weight*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e759940",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[[\"ID\", \"predicted_weight\"]]\n",
    "submission.to_csv(\"testing2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac12fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"testing2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b35b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rm_id  predicted_weight\n",
      "75    2130      6.009917e+06\n",
      "180   3865      2.117237e+06\n",
      "151   3126      1.819248e+06\n",
      "83    2140      1.670645e+06\n",
      "147   3122      1.637264e+06\n",
      "160   3282      1.525760e+06\n",
      "150   3125      1.462576e+06\n",
      "149   3124      1.024576e+06\n",
      "148   3123      1.002832e+06\n",
      "176   3781      9.871144e+05\n",
      "79    2134      6.253800e+05\n",
      "159   3265      4.949120e+05\n",
      "182   3901      4.429440e+05\n",
      "85    2142      3.663764e+05\n",
      "87    2144      2.637948e+05\n",
      "142   2981      2.551360e+05\n",
      "80    2135      2.384537e+05\n",
      "76    2131      2.293000e+05\n",
      "77    2132      1.388832e+05\n",
      "181   3883      1.175360e+05\n",
      "88    2145      1.114832e+05\n",
      "78    2133      1.029703e+05\n",
      "152   3142      9.710400e+04\n",
      "163   3421      9.254000e+04\n",
      "136   2741      9.111520e+04\n",
      "191   4263      8.025600e+04\n",
      "172   3642      5.952000e+04\n",
      "190   4222      5.915200e+04\n",
      "86    2143      5.849040e+04\n",
      "71    2125      3.602880e+04\n",
      "161   3362      2.980800e+04\n",
      "90    2147      2.336704e+04\n",
      "70    2124      1.680160e+04\n",
      "74    2129      1.331200e+04\n",
      "103   2161      5.184000e+03\n",
      "117   2341      0.000000e+00\n",
      "116   2323      0.000000e+00\n",
      "128   2402      0.000000e+00\n",
      "133   2521      0.000000e+00\n",
      "115   2322      0.000000e+00\n",
      "114   2304      0.000000e+00\n",
      "135   2601      0.000000e+00\n",
      "113   2302      0.000000e+00\n",
      "137   2742      0.000000e+00\n",
      "138   2761      0.000000e+00\n",
      "112   2285      0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "test_df = submission.merge(prediction_mapping, on=\"ID\")\n",
    "test_df = test_df.groupby(\"rm_id\", as_index=False).agg({\n",
    "    \"predicted_weight\": \"max\",\n",
    "}).sort_values(\"predicted_weight\", ascending=False)\n",
    "\n",
    "print(test_df[0:46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rm_id  predicted_weight\n",
      "75    2130      3.605950e+06\n",
      "180   3865      2.117237e+06\n",
      "151   3126      1.819248e+06\n",
      "83    2140      1.670645e+06\n",
      "147   3122      1.637264e+06\n",
      "..     ...               ...\n",
      "64    2001      0.000000e+00\n",
      "65    2061      0.000000e+00\n",
      "66    2102      0.000000e+00\n",
      "67    2121      0.000000e+00\n",
      "202   4501      0.000000e+00\n",
      "\n",
      "[203 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# SCALE SPECIFIC RM_ID DOWN\n",
    "testing_2130 = pd.read_csv(\"testing2025.csv\")\n",
    "testing_2130 = testing_2130.merge(prediction_mapping, on=\"ID\")\n",
    "\n",
    "testing_2130.loc[testing_2130['rm_id'] == 2130, 'predicted_weight'] *= 0.6\n",
    "\n",
    "testing = testing_2130.groupby(\"rm_id\", as_index=False).agg({\n",
    "    \"predicted_weight\": \"max\",\n",
    "}).sort_values(\"predicted_weight\", ascending=False)\n",
    "\n",
    "print(testing)\n",
    "testing_2130 = testing_2130[[\"ID\", \"predicted_weight\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8772cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2130.to_csv(\"testing2025_2130_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffee76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
