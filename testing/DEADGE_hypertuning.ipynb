{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981493db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import (\n",
    "    optimize_hyperparameters,\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53d50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "receivals = pd.read_csv(\"../data_cleaned/orders_with_receivals_detailed.csv\", parse_dates=['date_arrival', 'delivery_date'])\n",
    "# Filter out rows with missing rm_id or date_arrival\n",
    "receivals = receivals[receivals['rm_id'].notnull() & receivals['date_arrival'].notnull()]\n",
    "# date_arrival = actual date of receival, delivery_date = expected date of receival\n",
    "# lead_time = date_arrival - delivery_date\n",
    "# quantity  = quantity, net_weight = weight in kg (the actual target per day etc)\n",
    "selected = receivals[[\"rm_id\", \"date_arrival\", \"net_weight\", \"supplier_id\", \"delivery_date\", \"product_id_receival\", \"quantity\", \"lead_time\"]]\n",
    "# Filter out the selected rows where rm_id is null or date_arrival is null\n",
    "selected = selected[selected['rm_id'].notnull() & selected['date_arrival'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090369f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING TIME_IDX AND AGGREGATING TO DAILY LEVEL AND FILLING GAPS WITH 0 NET_WEIGHT RECEIVALS\n",
    "\n",
    "\n",
    "# make a copy and normalize date_arrival to date-only (drop time) so grouping is by year-month-day\n",
    "df_agg = selected.copy()\n",
    "# ensure date_arrival is a datetime and floor to day (sets time to 00:00:00)\n",
    "df_agg['date_arrival'] = df_agg['date_arrival'].dt.floor('D')\n",
    "# Remove timezone info if present\n",
    "df_agg['date_arrival'] = df_agg['date_arrival'].dt.tz_localize(None)\n",
    "\n",
    "df_agg = df_agg.groupby(['rm_id', 'date_arrival']).agg({\n",
    "    'net_weight': 'sum',\n",
    "    'quantity': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Add time_idx based on days since each rm_id's minimum date\n",
    "df_agg = df_agg.sort_values(['rm_id', 'date_arrival'])\n",
    "df_agg['local_time_idx'] = (df_agg['date_arrival'] - df_agg.groupby('rm_id')['date_arrival'].transform('min')).dt.days\n",
    "\n",
    "# Fill gaps from each rm_id's min date to 2024-12-31 with 0 net_weight entries\n",
    "end_date = pd.Timestamp('2024-12-31')\n",
    "all_filled = []\n",
    "\n",
    "for rm_id, group in df_agg.groupby('rm_id'):\n",
    "    min_date = group['date_arrival'].min()\n",
    "    max_idx = (end_date - min_date).days\n",
    "    \n",
    "    full_range = pd.DataFrame({\n",
    "        'local_time_idx': range(0, max_idx + 1)\n",
    "    })\n",
    "    full_range['rm_id'] = rm_id\n",
    "    full_range['date_arrival'] = min_date + pd.to_timedelta(full_range['local_time_idx'], unit='D')\n",
    "    \n",
    "    merged = pd.merge(full_range, group, on=['rm_id', 'local_time_idx', 'date_arrival'], how='left')\n",
    "    merged['net_weight'] = merged['net_weight'].fillna(0)\n",
    "    merged['quantity'] = merged['quantity'].fillna(0)\n",
    "  \n",
    "    all_filled.append(merged)\n",
    "\n",
    "df_agg = pd.concat(all_filled, ignore_index=True)\n",
    "selected_with_local_time = df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7841725f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        local_time_idx date_arrival  net_weight\n",
      "488659          4794.0   2024-12-30         0.0\n",
      "488660          4795.0   2024-12-31         0.0\n"
     ]
    }
   ],
   "source": [
    "print(selected_with_local_time.where(selected_with_local_time[\"rm_id\"]==2130).dropna()[[\"local_time_idx\", \"date_arrival\", \"net_weight\"]].tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5231dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional features\n",
    "selected_with_local_time[\"month\"] = selected_with_local_time[\"date_arrival\"].dt.month.astype(str).astype(\"category\")\n",
    "selected_with_local_time[\"year\"] = selected_with_local_time[\"date_arrival\"].dt.year.astype(str).astype(\"category\")\n",
    "selected_with_local_time[\"day_of_week\"] = selected_with_local_time[\"date_arrival\"].dt.dayofweek.astype(str).astype(\"category\")  # 0=Monday, 6=Sunday\n",
    "selected_with_local_time[\"log_weight\"] = np.log1p(selected_with_local_time[\"net_weight\"])\n",
    "\n",
    "# Norwegian special days/holidays\n",
    "# Fixed holidays\n",
    "def get_norwegian_holidays(year):\n",
    "    \"\"\"Return dictionary of Norwegian holidays for a given year\"\"\"\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    holidays = {}\n",
    "    \n",
    "    # Fixed date holidays\n",
    "    holidays[f'{year}-01-01'] = 'New Year'\n",
    "    holidays[f'{year}-05-01'] = 'Labour Day'\n",
    "    holidays[f'{year}-05-17'] = 'Constitution Day'\n",
    "    holidays[f'{year}-12-24'] = 'Christmas Eve'\n",
    "    holidays[f'{year}-12-25'] = 'Christmas Day'\n",
    "    holidays[f'{year}-12-26'] = 'Boxing Day'\n",
    "    holidays[f'{year}-12-31'] = 'New Year Eve'\n",
    "    \n",
    "    # Easter-based holidays (Easter dates vary each year)\n",
    "    # Approximate Easter calculation (Meeus/Jones/Butcher algorithm)\n",
    "    a = year % 19\n",
    "    b = year // 100\n",
    "    c = year % 100\n",
    "    d = b // 4\n",
    "    e = b % 4\n",
    "    f = (b + 8) // 25\n",
    "    g = (b - f + 1) // 3\n",
    "    h = (19 * a + b - d - g + 15) % 30\n",
    "    i = c // 4\n",
    "    k = c % 4\n",
    "    l = (32 + 2 * e + 2 * i - h - k) % 7\n",
    "    m = (a + 11 * h + 22 * l) // 451\n",
    "    month = (h + l - 7 * m + 114) // 31\n",
    "    day = ((h + l - 7 * m + 114) % 31) + 1\n",
    "    \n",
    "    easter = pd.Timestamp(year=year, month=month, day=day)\n",
    "    \n",
    "    # Easter-related holidays\n",
    "    holidays[(easter - timedelta(days=3)).strftime('%Y-%m-%d')] = 'Maundy Thursday'\n",
    "    holidays[(easter - timedelta(days=2)).strftime('%Y-%m-%d')] = 'Good Friday'\n",
    "    holidays[easter.strftime('%Y-%m-%d')] = 'Easter Sunday'\n",
    "    holidays[(easter + timedelta(days=1)).strftime('%Y-%m-%d')] = 'Easter Monday'\n",
    "    holidays[(easter + timedelta(days=39)).strftime('%Y-%m-%d')] = 'Ascension Day'\n",
    "    holidays[(easter + timedelta(days=49)).strftime('%Y-%m-%d')] = 'Whit Sunday'\n",
    "    holidays[(easter + timedelta(days=50)).strftime('%Y-%m-%d')] = 'Whit Monday'\n",
    "    \n",
    "    return holidays\n",
    "\n",
    "# Create a mapping of all dates to holidays\n",
    "all_holidays = {}\n",
    "for year in range(selected_with_local_time['date_arrival'].dt.year.min(), \n",
    "                  selected_with_local_time['date_arrival'].dt.year.max() + 1):\n",
    "    all_holidays.update(get_norwegian_holidays(year))\n",
    "\n",
    "# Add special day column\n",
    "selected_with_local_time['date_str'] = selected_with_local_time['date_arrival'].dt.strftime('%Y-%m-%d')\n",
    "selected_with_local_time['special_days'] = selected_with_local_time['date_str'].map(all_holidays).fillna('none').astype('category')\n",
    "selected_with_local_time.drop('date_str', axis=1, inplace=True)\n",
    "\n",
    "# Add binary flag for whether it's a holiday\n",
    "selected_with_local_time['is_holiday'] = (selected_with_local_time['special_days'] != 'none').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac019ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        local_time_idx   rm_id date_arrival  net_weight  quantity month  year  \\\n",
      "488659          4794.0  2130.0   2024-12-30         0.0       0.0    12  2024   \n",
      "488660          4795.0  2130.0   2024-12-31         0.0       0.0    12  2024   \n",
      "\n",
      "       day_of_week  log_weight  special_days  is_holiday  \n",
      "488659           0         0.0          none         0.0  \n",
      "488660           1         0.0  New Year Eve         1.0  \n"
     ]
    }
   ],
   "source": [
    "print(selected_with_local_time.where(selected_with_local_time[\"rm_id\"]==2130).dropna().tail(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca6def5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [local_time_idx, rm_id, date_arrival, net_weight, quantity, month, day_of_week, log_weight, special_days, is_holiday]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "special_days = list(all_holidays.values())\n",
    "\n",
    "# Make rm_id a string instead of numeric\n",
    "selected_with_local_time[\"rm_id\"] = selected_with_local_time[\"rm_id\"].astype(int).astype(str).astype(\"category\")\n",
    "selected_with_local_time[\"is_holiday\"] = selected_with_local_time[\"is_holiday\"].astype(str).astype(\"category\")\n",
    "selected_with_local_time.drop(\"year\", axis=1, inplace=True)\n",
    "print(selected_with_local_time.head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3461', '4161', '4222', '4263', '4302', '4343', '4381', '4401', '4441', '4443', '4461', '4462', '4463', '4481', '4501']\n",
      "        local_time_idx rm_id date_arrival  net_weight   quantity month  \\\n",
      "488507            4642  2130   2024-07-31     76360.0  7800000.0     7   \n",
      "488508            4643  2130   2024-08-01    110021.0  5600000.0     8   \n",
      "\n",
      "       day_of_week  log_weight special_days is_holiday  \n",
      "488507           2   11.243227         none          0  \n",
      "488508           3   11.608436         none          0  \n",
      "(152, 10)\n",
      "(4644, 10)\n"
     ]
    }
   ],
   "source": [
    "full_data = selected_with_local_time.copy()\n",
    "\n",
    "def add_cutoff_per_group(df, group_col, max_pred_len):\n",
    "    local_cutoffs = (\n",
    "        df.groupby(group_col)[\"local_time_idx\"].transform(\"max\") - max_pred_len\n",
    "    )\n",
    "    df[\"is_val\"] = df[\"local_time_idx\"] > local_cutoffs\n",
    "    return df\n",
    "\n",
    "max_prediction_length = 152\n",
    "max_encoder_length = 366\n",
    "full_data = add_cutoff_per_group(full_data, \"rm_id\", max_prediction_length)\n",
    "\n",
    "validation_set = full_data[full_data[\"is_val\"]].copy()\n",
    "validation_set = validation_set.drop(\"is_val\", axis=1)\n",
    "training_set = full_data[~full_data[\"is_val\"]].copy()\n",
    "training_set = training_set.drop(\"is_val\", axis=1)\n",
    "\n",
    "too_small_data_rm_ids = []  # rm ids in full_data that have less than max_encoder_length + max_prediction_length entries in training set[]\n",
    "for rm_id, group in training_set.groupby(\"rm_id\"):\n",
    "    if len(group) <max_prediction_length+1:\n",
    "        too_small_data_rm_ids.append(rm_id)\n",
    "\n",
    "print(too_small_data_rm_ids)\n",
    "\n",
    "training_set = training_set[~training_set[\"rm_id\"].isin(too_small_data_rm_ids)].copy()\n",
    "validation_set = validation_set[~validation_set[\"rm_id\"].isin(too_small_data_rm_ids)].copy()\n",
    "\n",
    "print(training_set[training_set[\"rm_id\"]==\"2130\"].tail(2))\n",
    "\n",
    "print(validation_set[validation_set[\"rm_id\"]==\"2130\"].shape)\n",
    "print(training_set[training_set[\"rm_id\"]==\"2130\"].shape)\n",
    "\n",
    "\n",
    "full_data = pd.concat([training_set, validation_set], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280b1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    data = training_set,\n",
    "    time_idx=\"local_time_idx\",\n",
    "    target=\"net_weight\",\n",
    "    group_ids=[\"rm_id\"],\n",
    "    min_encoder_length=max_encoder_length\n",
    "    // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"rm_id\"],\n",
    "    #static_reals= no static real yet,\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\", \"day_of_week\", \"is_holiday\"],\n",
    "    #variable_groups={\n",
    "    #    \"special_days\": special_days\n",
    "    #},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"local_time_idx\"],\n",
    "    # CAN PUT YEAR IN TIME_VARYING_KNOWN_REALS\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"quantity\",\n",
    "        \"net_weight\",\n",
    "        \"log_weight\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"rm_id\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training, data=full_data, predict=True, stop_randomization=True\n",
    ")\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=0\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size * 10, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe158c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 10.4k\n"
     ]
    }
   ],
   "source": [
    "# TRAINING THE MODEL\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\"\n",
    ")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=500,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,\n",
    "    #fast_dev_run = True,\n",
    "    callbacks=[lr_logger],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.001,\n",
    "    hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    optimizer=\"ranger\",  # OPTIMIZER FOR FINDING BEST LEARNING RATE\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c70469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.7 K  | train\n",
      "3  | prescalers                         | ModuleDict                      | 128    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.2 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 2.5 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.2 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 304    | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 304    | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 304    | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 304    | train\n",
      "11 | lstm_encoder                       | LSTM                            | 576    | train\n",
      "12 | lstm_decoder                       | LSTM                            | 576    | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 144    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 16     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 368    | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 280    | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 160    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 304    | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 160    | train\n",
      "20 | output_layer                       | Linear                          | 63     | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "10.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n",
      "303       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.44it/s, v_num=3, train_loss_step=548.0, val_loss=567.0, train_loss_epoch=880.0]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.44it/s, v_num=3, train_loss_step=548.0, val_loss=567.0, train_loss_epoch=880.0]\n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:52<00:00,  1.79it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:52<00:00,  1.90it/s]\n",
      "Restoring states from the checkpoint path at c:\\Users\\david\\OneDrive\\Skrivebord\\ML append project\\append_consulting_project\\testing\\.lr_find_f2f9541a-303e-4730-99f5-d1afe9ca9f85.ckpt\n",
      "Restored all states from the checkpoint at c:\\Users\\david\\OneDrive\\Skrivebord\\ML append project\\append_consulting_project\\testing\\.lr_find_f2f9541a-303e-4730-99f5-d1afe9ca9f85.ckpt\n",
      "Learning rate set to 6.918309709189363e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 6.918309709189363e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOU SHOULD DO THIS CAUSE THE OPTIMAL\n",
    "# LEARNING RATE PYTORCH LIGHTNING COULD\n",
    "# SOMETIMES BE CONFUSED BY THE NOISE AT LOWER LEARNING RATES\n",
    "# AND SUGGESTS RATES FAR TOO LOW. MANUAL CONTROL IS ESSENTIAL\n",
    "# # find optimal learning rate\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "     tft,\n",
    "     train_dataloaders=train_dataloader,\n",
    "     val_dataloaders=val_dataloader,                                        \n",
    "     max_lr=10.0,\n",
    "     min_lr=1e-6,\n",
    " )\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf58e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-18 23:33:28,017] A new study created in memory with name: no-name-871a9b97-0525-423d-9c78-a0cb3868d127\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2025-10-18 23:56:24,794] Trial 0 finished with value: 561.6035766601562 and parameters: {'gradient_clip_val': 0.05550251786786674, 'hidden_size': 11, 'dropout': 0.2352490848087136, 'hidden_continuous_size': 11, 'attention_head_size': 1, 'learning_rate': 0.03338777348411531}. Best is trial 0 with value: 561.6035766601562.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2025-10-19 00:48:38,416] Trial 1 finished with value: 500.4615478515625 and parameters: {'gradient_clip_val': 0.4183264961564628, 'hidden_size': 28, 'dropout': 0.2890662323894735, 'hidden_continuous_size': 15, 'attention_head_size': 1, 'learning_rate': 0.0015532877747649432}. Best is trial 1 with value: 500.4615478515625.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2025-10-19 01:39:45,354] Trial 2 finished with value: 449.2545166015625 and parameters: {'gradient_clip_val': 0.012179320703577733, 'hidden_size': 29, 'dropout': 0.12469376786070158, 'hidden_continuous_size': 14, 'attention_head_size': 1, 'learning_rate': 0.004342145465626561}. Best is trial 2 with value: 449.2545166015625.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 01:44:11,304] Trial 3 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 01:46:09,364] Trial 4 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 01:52:53,534] Trial 5 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:01:32,290] Trial 6 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:02:27,550] Trial 7 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:03:23,690] Trial 8 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:06:43,292] Trial 9 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:13:29,378] Trial 10 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:15:08,372] Trial 11 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:16:24,790] Trial 12 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:19:08,050] Trial 13 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:30:13,239] Trial 14 pruned. Trial was pruned at epoch 16.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:32:29,261] Trial 15 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:33:11,103] Trial 16 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:46:34,990] Trial 17 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:47:39,089] Trial 18 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 02:59:50,290] Trial 19 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:02:18,875] Trial 20 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:03:03,947] Trial 21 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:03:51,965] Trial 22 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:05:21,265] Trial 23 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:08:40,372] Trial 24 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:09:27,595] Trial 25 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:11:30,714] Trial 26 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:12:25,382] Trial 27 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:13:26,553] Trial 28 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:15:03,646] Trial 29 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:38:35,652] Trial 30 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:50:32,437] Trial 31 pruned. Trial was pruned at epoch 16.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:55:30,581] Trial 32 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:56:52,311] Trial 33 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 03:57:39,221] Trial 34 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:20:12,611] Trial 35 pruned. Trial was pruned at epoch 16.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:22:51,283] Trial 36 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:23:50,280] Trial 37 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:27:14,775] Trial 38 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:39:36,644] Trial 39 pruned. Trial was pruned at epoch 16.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:41:22,695] Trial 40 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:44:30,727] Trial 41 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:45:50,433] Trial 42 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:47:31,173] Trial 43 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:48:24,227] Trial 44 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:50:34,116] Trial 45 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:52:51,980] Trial 46 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:53:31,999] Trial 47 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:56:03,988] Trial 48 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 04:58:45,201] Trial 49 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:00:08,619] Trial 50 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:01:30,469] Trial 51 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:03:20,557] Trial 52 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:04:40,588] Trial 53 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:06:09,770] Trial 54 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:07:49,616] Trial 55 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:08:53,781] Trial 56 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:12:07,834] Trial 57 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:14:08,390] Trial 58 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:14:57,594] Trial 59 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:52:25,799] Trial 60 pruned. Trial was pruned at epoch 16.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:54:55,477] Trial 61 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:56:58,922] Trial 62 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 05:59:35,803] Trial 63 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:05:55,515] Trial 64 pruned. Trial was pruned at epoch 16.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:07:51,198] Trial 65 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:08:29,688] Trial 66 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:09:16,760] Trial 67 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:10:02,410] Trial 68 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:10:46,873] Trial 69 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:11:28,118] Trial 70 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:13:08,541] Trial 71 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:17:10,756] Trial 72 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:18:25,244] Trial 73 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:20:41,910] Trial 74 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:21:49,862] Trial 75 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:23:53,852] Trial 76 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:27:37,086] Trial 77 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:28:37,614] Trial 78 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:31:35,999] Trial 79 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:32:21,287] Trial 80 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:37:35,640] Trial 81 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 06:59:10,005] Trial 82 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:04:26,670] Trial 83 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:08:53,421] Trial 84 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:12:30,624] Trial 85 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:20:32,335] Trial 86 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:24:58,823] Trial 87 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:25:58,854] Trial 88 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:26:48,982] Trial 89 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:28:23,459] Trial 90 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:29:08,387] Trial 91 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:30:22,973] Trial 92 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:31:18,428] Trial 93 pruned. Trial was pruned at epoch 1.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:33:23,555] Trial 94 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[I 2025-10-19 07:34:45,356] Trial 95 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_clip_val': 0.012179320703577733, 'hidden_size': 29, 'dropout': 0.12469376786070158, 'hidden_continuous_size': 14, 'attention_head_size': 1, 'learning_rate': 0.004342145465626561}\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETER TUNING WITH OPTUNA\n",
    "\n",
    "import pickle\n",
    "\n",
    "import optuna\n",
    "import optuna_integration\n",
    "import statsmodels\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "027a4533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction dataframe shape: (101473, 10)\n",
      "Date range: 2024-01-02 00:00:00 to 2025-05-31 00:00:00\n",
      "Time index range: 0 to 7655\n",
      "\n",
      "First few rows:\n",
      "   local_time_idx rm_id date_arrival  net_weight  quantity month day_of_week  \\\n",
      "0            7132   342   2024-01-02         0.0       0.0     1           1   \n",
      "1            7133   342   2024-01-03         0.0       0.0     1           2   \n",
      "2            7134   342   2024-01-04         0.0       0.0     1           3   \n",
      "3            7135   342   2024-01-05         0.0       0.0     1           4   \n",
      "4            7136   342   2024-01-06         0.0       0.0     1           5   \n",
      "\n",
      "   log_weight special_days is_holiday  \n",
      "0         0.0         none          0  \n",
      "1         0.0         none          0  \n",
      "2         0.0         none          0  \n",
      "3         0.0         none          0  \n",
      "4         0.0         none          0  \n"
     ]
    }
   ],
   "source": [
    "################# FULLL PREDICTION FOR ALL RM_IDs ###############\n",
    "\n",
    "\n",
    "rm_ids = full_data['rm_id'].unique().tolist()\n",
    "predict_data = []\n",
    "# Create prediction date range\n",
    "pred_start = pd.Timestamp('2025-01-01')\n",
    "pred_end = pd.Timestamp('2025-05-31')\n",
    "pred_dates = pd.date_range(start=pred_start, end=pred_end, freq='D')\n",
    "\n",
    "all_predict_dfs = []\n",
    "\n",
    "for rm_id in rm_ids:\n",
    "    test_rm_id = rm_id  # must match categorical rm_id type\n",
    "    historical = full_data[full_data['rm_id'] == test_rm_id].copy()\n",
    "    if historical.empty:\n",
    "        continue\n",
    "    min_date = historical['date_arrival'].min()\n",
    "\n",
    "    # build prediction rows for this rm_id\n",
    "    rows = []\n",
    "    for date in pred_dates:\n",
    "        time_idx = (date - min_date).days\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        special_day = all_holidays.get(date_str, 'none')\n",
    "        is_holiday = '1' if special_day != 'none' else '0'\n",
    "\n",
    "        rows.append({\n",
    "            'rm_id': test_rm_id,\n",
    "            'date_arrival': date,\n",
    "            'local_time_idx': time_idx,\n",
    "            'month': str(date.month),\n",
    "            'day_of_week': str(date.dayofweek),\n",
    "            'special_days': special_day,\n",
    "            'is_holiday': is_holiday,\n",
    "            'net_weight': 0,   # placeholder\n",
    "            'quantity': 0,     # placeholder\n",
    "            'log_weight': 0    # placeholder\n",
    "        })\n",
    "\n",
    "    pred_df_rm = pd.DataFrame(rows)\n",
    "\n",
    "    # encoder/context data (last max_encoder_length days)\n",
    "    encoder_data = historical.tail(max_encoder_length).copy()\n",
    "    encoder_data['local_time_idx'] = encoder_data['local_time_idx'].astype(int)\n",
    "\n",
    "    # combine encoder + prediction for this rm_id and collect\n",
    "    combined = pd.concat([encoder_data, pred_df_rm], ignore_index=True)\n",
    "    all_predict_dfs.append(combined)\n",
    "\n",
    "# final combined prediction dataframe for all rm_ids\n",
    "predict_data = pd.concat(all_predict_dfs, ignore_index=True)\n",
    "\n",
    "predict_data = pd.DataFrame(predict_data)\n",
    "\n",
    "# Convert to categorical to match training data\n",
    "predict_data['rm_id'] = predict_data['rm_id'].astype(str).astype('category')\n",
    "predict_data['month'] = predict_data['month'].astype(str).astype('category')\n",
    "predict_data['day_of_week'] = predict_data['day_of_week'].astype(str).astype('category')\n",
    "predict_data['special_days'] = predict_data['special_days'].astype(str).astype('category')\n",
    "predict_data['is_holiday'] = predict_data['is_holiday'].astype(str).astype('category')\n",
    "\n",
    "# Ensure local_time_idx is integer (required by TimeSeriesDataSet)\n",
    "predict_data['local_time_idx'] = predict_data['local_time_idx'].astype(int)\n",
    "\n",
    "print(f\"Prediction dataframe shape: {predict_data.shape}\")\n",
    "print(f\"Date range: {predict_data['date_arrival'].min()} to {predict_data['date_arrival'].max()}\")\n",
    "print(f\"Time index range: {predict_data['local_time_idx'].min()} to {predict_data['local_time_idx'].max()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(predict_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7cf0babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "predictions = tft.predict(predict_data, return_x=True, return_index=True, return_decoder_lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltdx_and_rmid = predictions.index\n",
    "\n",
    "output = predictions.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2760e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "pred_start = pd.Timestamp('2025-01-01')\n",
    "pred_end = pd.Timestamp('2025-05-31')\n",
    "pred_dates = pd.date_range(start=pred_start, end=pred_end, freq='D')\n",
    "\n",
    "\n",
    "for rm_id_index in range(0,192):\n",
    "    rm_id_test = ltdx_and_rmid[\"rm_id\"][rm_id_index]\n",
    "    ltdx_test = ltdx_and_rmid[\"local_time_idx\"][rm_id_index]\n",
    "    for date in pred_dates:\n",
    "        pred_weight = output[rm_id_index][(date-pred_start).days].item()\n",
    "        pred.append({\n",
    "            \"rm_id\": rm_id_test,\n",
    "            \"local_time_idx\": ltdx_test,\n",
    "            \"date\": date,\n",
    "            \"predicted_weight\": pred_weight\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bac78deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [rm_id, local_time_idx, date, predicted_weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "pred = pd.DataFrame(pred)\n",
    "pred_over_0 = pred[pred[\"predicted_weight\"]>0]\n",
    "print(pred_over_0.head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5ed43fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "prediction_mapping = pd.read_csv(\"../data/prediction_mapping.csv\")\n",
    "\n",
    "submission = sample_submission.merge(prediction_mapping, on=\"ID\")\n",
    "submission[\"forecast_end_date\"] = pd.to_datetime(submission[\"forecast_end_date\"])\n",
    "submission[\"forecast_start_date\"] = pd.to_datetime(submission[\"forecast_start_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f3de1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pred_over_0.itertuples():\n",
    "    rm_id = p.rm_id\n",
    "    date_arrival = p.date.replace(tzinfo=None)\n",
    "    predicted_weight = p.predicted_weight\n",
    "    submission.loc[\n",
    "        (submission['rm_id'] == int(rm_id)) & (submission['forecast_end_date'] >= date_arrival),\n",
    "        'predicted_weight'\n",
    "    ] += predicted_weight*0.8  # applying a scaling factor of 0.8 to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fae9f7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  predicted_weight  rm_id forecast_start_date forecast_end_date\n",
      "4050    4051      5.764381e-42    387          2025-01-01        2025-01-02\n",
      "4051    4052      9.533314e-42    387          2025-01-01        2025-01-03\n",
      "4052    4053      1.411388e-41    387          2025-01-01        2025-01-04\n",
      "4053    4054      1.833795e-41    387          2025-01-01        2025-01-05\n",
      "4054    4055      2.091410e-41    387          2025-01-01        2025-01-06\n",
      "...      ...               ...    ...                 ...               ...\n",
      "28495  28496      1.172021e+05   4222          2025-01-01        2025-05-27\n",
      "28496  28497      1.195251e+05   4222          2025-01-01        2025-05-28\n",
      "28497  28498      1.220258e+05   4222          2025-01-01        2025-05-29\n",
      "28498  28499      1.239892e+05   4222          2025-01-01        2025-05-30\n",
      "28499  28500      1.239892e+05   4222          2025-01-01        2025-05-31\n",
      "\n",
      "[3030 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(submission[submission[\"predicted_weight\"]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c45a0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rm_id  local_time_idx       date  predicted_weight\n",
      "6644   2130            4796 2025-01-01      41310.648438\n",
      "6645   2130            4796 2025-01-02      62216.707031\n",
      "6646   2130            4796 2025-01-03      68784.070312\n",
      "6649   2130            4796 2025-01-06      65307.386719\n",
      "6650   2130            4796 2025-01-07      75567.210938\n",
      "...     ...             ...        ...               ...\n",
      "28681  4222             266 2025-05-23       2406.461670\n",
      "28685  4222             266 2025-05-27       3211.144531\n",
      "28686  4222             266 2025-05-28       2903.663086\n",
      "28687  4222             266 2025-05-29       3125.951172\n",
      "28688  4222             266 2025-05-30       2454.265625\n",
      "\n",
      "[1882 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pred_over_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e96ba908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  predicted_weight  rm_id forecast_start_date forecast_end_date\n",
      "0          1                 0    365          2025-01-01        2025-01-02\n",
      "1          2                 0    365          2025-01-01        2025-01-03\n",
      "2          3                 0    365          2025-01-01        2025-01-04\n",
      "3          4                 0    365          2025-01-01        2025-01-05\n",
      "4          5                 0    365          2025-01-01        2025-01-06\n",
      "...      ...               ...    ...                 ...               ...\n",
      "30445  30446                 0   4501          2025-01-01        2025-05-27\n",
      "30446  30447                 0   4501          2025-01-01        2025-05-28\n",
      "30447  30448                 0   4501          2025-01-01        2025-05-29\n",
      "30448  30449                 0   4501          2025-01-01        2025-05-30\n",
      "30449  30450                 0   4501          2025-01-01        2025-05-31\n",
      "\n",
      "[30450 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7f7ad6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = submission.copy()\n",
    "\n",
    "agg_df = filtered.groupby(\"rm_id\", as_index=False).agg({\n",
    "    \"predicted_weight\": \"max\",\n",
    "}).sort_values(\"predicted_weight\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1819ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_final = submission[[\"ID\", \"predicted_weight\"]]\n",
    "submission_final.to_csv(\"DEADGE_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799561c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
